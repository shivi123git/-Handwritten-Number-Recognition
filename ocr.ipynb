{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkRnDLrkCiPyKzmP2cFWR+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivi123git/-Handwritten-Number-Recognition/blob/main/ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_SqM7yBsLYi"
      },
      "outputs": [],
      "source": [
        "import torch #libraries  then other datasets available that provide us the examples we need to teach the machine\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST( #where  you download the datasets, go to internet and then download into a folder called data\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "#you can use the same code but use different datasets with pictures\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(\n",
        "        train_data,\n",
        "        batch_size=100,\n",
        "        shuffle=True,\n",
        "        num_workers=1\n",
        "    ),\n",
        "\n",
        "    'test': DataLoader(\n",
        "        test_data,\n",
        "        batch_size=100,\n",
        "        shuffle=True,\n",
        "        num_workers=1\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "EBQ2KayQsdbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a33062a-2e49-4d9e-afea-b763da49301e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 22.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 644kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.68MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.47MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module): #convulsional neural network : filter that goes over picture to extract certain details --> goes to every single picture and look at a number and identify all its patterns/lines/curves from all examples,\n",
        "    #we write a class (group of functions), read all images and find patterns\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) #kernel size: 5 by 5 box --> larger the kernel, the more detailed\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()    #all of these settings makes it deeper and more details --> this creates higher accuracy\n",
        "        self.fc1 = nn.Linear(320, 50)  #the deeper the network, the more neurons the machine will have\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.softmax(x)"
      ],
      "metadata": {
        "id": "YrGg9HZRsgRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch): #training process: slowest part\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6f}\")\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss = loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'].dataset)\n",
        "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%\\n)\")\n",
        "\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQEC-5jEskyL",
        "outputId": "85ff66d1-3405-4d1b-fd55-237e8545df16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-79c0fb43b5ab>:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\t2.303108\n",
            "Train Epoch: 1 [2000/60000 (3%)]\t2.292573\n",
            "Train Epoch: 1 [4000/60000 (7%)]\t2.237589\n",
            "Train Epoch: 1 [6000/60000 (10%)]\t2.048379\n",
            "Train Epoch: 1 [8000/60000 (13%)]\t1.826895\n",
            "Train Epoch: 1 [10000/60000 (17%)]\t1.781853\n",
            "Train Epoch: 1 [12000/60000 (20%)]\t1.791076\n",
            "Train Epoch: 1 [14000/60000 (23%)]\t1.738614\n",
            "Train Epoch: 1 [16000/60000 (27%)]\t1.783755\n",
            "Train Epoch: 1 [18000/60000 (30%)]\t1.647878\n",
            "Train Epoch: 1 [20000/60000 (33%)]\t1.699991\n",
            "Train Epoch: 1 [22000/60000 (37%)]\t1.687972\n",
            "Train Epoch: 1 [24000/60000 (40%)]\t1.625262\n",
            "Train Epoch: 1 [26000/60000 (43%)]\t1.612355\n",
            "Train Epoch: 1 [28000/60000 (47%)]\t1.653500\n",
            "Train Epoch: 1 [30000/60000 (50%)]\t1.601785\n",
            "Train Epoch: 1 [32000/60000 (53%)]\t1.626933\n",
            "Train Epoch: 1 [34000/60000 (57%)]\t1.649517\n",
            "Train Epoch: 1 [36000/60000 (60%)]\t1.623615\n",
            "Train Epoch: 1 [38000/60000 (63%)]\t1.649185\n",
            "Train Epoch: 1 [40000/60000 (67%)]\t1.576519\n",
            "Train Epoch: 1 [42000/60000 (70%)]\t1.604752\n",
            "Train Epoch: 1 [44000/60000 (73%)]\t1.579579\n",
            "Train Epoch: 1 [46000/60000 (77%)]\t1.639533\n",
            "Train Epoch: 1 [48000/60000 (80%)]\t1.600751\n",
            "Train Epoch: 1 [50000/60000 (83%)]\t1.561479\n",
            "Train Epoch: 1 [52000/60000 (87%)]\t1.620015\n",
            "Train Epoch: 1 [54000/60000 (90%)]\t1.579060\n",
            "Train Epoch: 1 [56000/60000 (93%)]\t1.637507\n",
            "Train Epoch: 1 [58000/60000 (97%)]\t1.605632\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy 9404/10000 (94%\n",
            ")\n",
            "Train Epoch: 2 [0/60000 (0%)]\t1.571355\n",
            "Train Epoch: 2 [2000/60000 (3%)]\t1.612056\n",
            "Train Epoch: 2 [4000/60000 (7%)]\t1.558519\n",
            "Train Epoch: 2 [6000/60000 (10%)]\t1.563919\n",
            "Train Epoch: 2 [8000/60000 (13%)]\t1.565001\n",
            "Train Epoch: 2 [10000/60000 (17%)]\t1.541481\n",
            "Train Epoch: 2 [12000/60000 (20%)]\t1.577300\n",
            "Train Epoch: 2 [14000/60000 (23%)]\t1.603704\n",
            "Train Epoch: 2 [16000/60000 (27%)]\t1.586638\n",
            "Train Epoch: 2 [18000/60000 (30%)]\t1.558348\n",
            "Train Epoch: 2 [20000/60000 (33%)]\t1.571506\n",
            "Train Epoch: 2 [22000/60000 (37%)]\t1.575493\n",
            "Train Epoch: 2 [24000/60000 (40%)]\t1.567161\n",
            "Train Epoch: 2 [26000/60000 (43%)]\t1.571375\n",
            "Train Epoch: 2 [28000/60000 (47%)]\t1.603726\n",
            "Train Epoch: 2 [30000/60000 (50%)]\t1.579039\n",
            "Train Epoch: 2 [32000/60000 (53%)]\t1.592247\n",
            "Train Epoch: 2 [34000/60000 (57%)]\t1.571547\n",
            "Train Epoch: 2 [36000/60000 (60%)]\t1.541829\n",
            "Train Epoch: 2 [38000/60000 (63%)]\t1.490911\n",
            "Train Epoch: 2 [40000/60000 (67%)]\t1.573676\n",
            "Train Epoch: 2 [42000/60000 (70%)]\t1.564980\n",
            "Train Epoch: 2 [44000/60000 (73%)]\t1.533543\n",
            "Train Epoch: 2 [46000/60000 (77%)]\t1.525508\n",
            "Train Epoch: 2 [48000/60000 (80%)]\t1.567776\n",
            "Train Epoch: 2 [50000/60000 (83%)]\t1.554254\n",
            "Train Epoch: 2 [52000/60000 (87%)]\t1.595608\n",
            "Train Epoch: 2 [54000/60000 (90%)]\t1.545474\n",
            "Train Epoch: 2 [56000/60000 (93%)]\t1.571863\n",
            "Train Epoch: 2 [58000/60000 (97%)]\t1.538882\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9551/10000 (96%\n",
            ")\n",
            "Train Epoch: 3 [0/60000 (0%)]\t1.593865\n",
            "Train Epoch: 3 [2000/60000 (3%)]\t1.547394\n",
            "Train Epoch: 3 [4000/60000 (7%)]\t1.570105\n",
            "Train Epoch: 3 [6000/60000 (10%)]\t1.568749\n",
            "Train Epoch: 3 [8000/60000 (13%)]\t1.551782\n",
            "Train Epoch: 3 [10000/60000 (17%)]\t1.544198\n",
            "Train Epoch: 3 [12000/60000 (20%)]\t1.547436\n",
            "Train Epoch: 3 [14000/60000 (23%)]\t1.591661\n",
            "Train Epoch: 3 [16000/60000 (27%)]\t1.536105\n",
            "Train Epoch: 3 [18000/60000 (30%)]\t1.530960\n",
            "Train Epoch: 3 [20000/60000 (33%)]\t1.600534\n",
            "Train Epoch: 3 [22000/60000 (37%)]\t1.576492\n",
            "Train Epoch: 3 [24000/60000 (40%)]\t1.525286\n",
            "Train Epoch: 3 [26000/60000 (43%)]\t1.530045\n",
            "Train Epoch: 3 [28000/60000 (47%)]\t1.544777\n",
            "Train Epoch: 3 [30000/60000 (50%)]\t1.525986\n",
            "Train Epoch: 3 [32000/60000 (53%)]\t1.544725\n",
            "Train Epoch: 3 [34000/60000 (57%)]\t1.510265\n",
            "Train Epoch: 3 [36000/60000 (60%)]\t1.547675\n",
            "Train Epoch: 3 [38000/60000 (63%)]\t1.553867\n",
            "Train Epoch: 3 [40000/60000 (67%)]\t1.527076\n",
            "Train Epoch: 3 [42000/60000 (70%)]\t1.520471\n",
            "Train Epoch: 3 [44000/60000 (73%)]\t1.565699\n",
            "Train Epoch: 3 [46000/60000 (77%)]\t1.541069\n",
            "Train Epoch: 3 [48000/60000 (80%)]\t1.604460\n",
            "Train Epoch: 3 [50000/60000 (83%)]\t1.543534\n",
            "Train Epoch: 3 [52000/60000 (87%)]\t1.549740\n",
            "Train Epoch: 3 [54000/60000 (90%)]\t1.523446\n",
            "Train Epoch: 3 [56000/60000 (93%)]\t1.598847\n",
            "Train Epoch: 3 [58000/60000 (97%)]\t1.531702\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy 9608/10000 (96%\n",
            ")\n",
            "Train Epoch: 4 [0/60000 (0%)]\t1.537354\n",
            "Train Epoch: 4 [2000/60000 (3%)]\t1.566846\n",
            "Train Epoch: 4 [4000/60000 (7%)]\t1.559519\n",
            "Train Epoch: 4 [6000/60000 (10%)]\t1.575433\n",
            "Train Epoch: 4 [8000/60000 (13%)]\t1.564447\n",
            "Train Epoch: 4 [10000/60000 (17%)]\t1.554332\n",
            "Train Epoch: 4 [12000/60000 (20%)]\t1.496179\n",
            "Train Epoch: 4 [14000/60000 (23%)]\t1.549932\n",
            "Train Epoch: 4 [16000/60000 (27%)]\t1.565539\n",
            "Train Epoch: 4 [18000/60000 (30%)]\t1.557972\n",
            "Train Epoch: 4 [20000/60000 (33%)]\t1.547364\n",
            "Train Epoch: 4 [22000/60000 (37%)]\t1.539208\n",
            "Train Epoch: 4 [24000/60000 (40%)]\t1.528258\n",
            "Train Epoch: 4 [26000/60000 (43%)]\t1.547552\n",
            "Train Epoch: 4 [28000/60000 (47%)]\t1.546532\n",
            "Train Epoch: 4 [30000/60000 (50%)]\t1.540749\n",
            "Train Epoch: 4 [32000/60000 (53%)]\t1.531434\n",
            "Train Epoch: 4 [34000/60000 (57%)]\t1.575401\n",
            "Train Epoch: 4 [36000/60000 (60%)]\t1.562038\n",
            "Train Epoch: 4 [38000/60000 (63%)]\t1.522789\n",
            "Train Epoch: 4 [40000/60000 (67%)]\t1.576705\n",
            "Train Epoch: 4 [42000/60000 (70%)]\t1.564779\n",
            "Train Epoch: 4 [44000/60000 (73%)]\t1.490338\n",
            "Train Epoch: 4 [46000/60000 (77%)]\t1.579023\n",
            "Train Epoch: 4 [48000/60000 (80%)]\t1.569844\n",
            "Train Epoch: 4 [50000/60000 (83%)]\t1.580834\n",
            "Train Epoch: 4 [52000/60000 (87%)]\t1.535017\n",
            "Train Epoch: 4 [54000/60000 (90%)]\t1.537983\n",
            "Train Epoch: 4 [56000/60000 (93%)]\t1.540442\n",
            "Train Epoch: 4 [58000/60000 (97%)]\t1.512915\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy 9659/10000 (97%\n",
            ")\n",
            "Train Epoch: 5 [0/60000 (0%)]\t1.532105\n",
            "Train Epoch: 5 [2000/60000 (3%)]\t1.522682\n",
            "Train Epoch: 5 [4000/60000 (7%)]\t1.554845\n",
            "Train Epoch: 5 [6000/60000 (10%)]\t1.591480\n",
            "Train Epoch: 5 [8000/60000 (13%)]\t1.559845\n",
            "Train Epoch: 5 [10000/60000 (17%)]\t1.531882\n",
            "Train Epoch: 5 [12000/60000 (20%)]\t1.543439\n",
            "Train Epoch: 5 [14000/60000 (23%)]\t1.551467\n",
            "Train Epoch: 5 [16000/60000 (27%)]\t1.513873\n",
            "Train Epoch: 5 [18000/60000 (30%)]\t1.521234\n",
            "Train Epoch: 5 [20000/60000 (33%)]\t1.502611\n",
            "Train Epoch: 5 [22000/60000 (37%)]\t1.482500\n",
            "Train Epoch: 5 [24000/60000 (40%)]\t1.519824\n",
            "Train Epoch: 5 [26000/60000 (43%)]\t1.544704\n",
            "Train Epoch: 5 [28000/60000 (47%)]\t1.522873\n",
            "Train Epoch: 5 [30000/60000 (50%)]\t1.533399\n",
            "Train Epoch: 5 [32000/60000 (53%)]\t1.540807\n",
            "Train Epoch: 5 [34000/60000 (57%)]\t1.536326\n",
            "Train Epoch: 5 [36000/60000 (60%)]\t1.510009\n",
            "Train Epoch: 5 [38000/60000 (63%)]\t1.527602\n",
            "Train Epoch: 5 [40000/60000 (67%)]\t1.538944\n",
            "Train Epoch: 5 [42000/60000 (70%)]\t1.552881\n",
            "Train Epoch: 5 [44000/60000 (73%)]\t1.561388\n",
            "Train Epoch: 5 [46000/60000 (77%)]\t1.509582\n",
            "Train Epoch: 5 [48000/60000 (80%)]\t1.540297\n",
            "Train Epoch: 5 [50000/60000 (83%)]\t1.523260\n",
            "Train Epoch: 5 [52000/60000 (87%)]\t1.511255\n",
            "Train Epoch: 5 [54000/60000 (90%)]\t1.529510\n",
            "Train Epoch: 5 [56000/60000 (93%)]\t1.602850\n",
            "Train Epoch: 5 [58000/60000 (97%)]\t1.514686\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9686/10000 (97%\n",
            ")\n",
            "Train Epoch: 6 [0/60000 (0%)]\t1.546625\n",
            "Train Epoch: 6 [2000/60000 (3%)]\t1.548156\n",
            "Train Epoch: 6 [4000/60000 (7%)]\t1.546894\n",
            "Train Epoch: 6 [6000/60000 (10%)]\t1.572761\n",
            "Train Epoch: 6 [8000/60000 (13%)]\t1.556460\n",
            "Train Epoch: 6 [10000/60000 (17%)]\t1.511101\n",
            "Train Epoch: 6 [12000/60000 (20%)]\t1.578380\n",
            "Train Epoch: 6 [14000/60000 (23%)]\t1.540960\n",
            "Train Epoch: 6 [16000/60000 (27%)]\t1.538178\n",
            "Train Epoch: 6 [18000/60000 (30%)]\t1.586174\n",
            "Train Epoch: 6 [20000/60000 (33%)]\t1.516735\n",
            "Train Epoch: 6 [22000/60000 (37%)]\t1.560613\n",
            "Train Epoch: 6 [24000/60000 (40%)]\t1.546918\n",
            "Train Epoch: 6 [26000/60000 (43%)]\t1.517776\n",
            "Train Epoch: 6 [28000/60000 (47%)]\t1.541693\n",
            "Train Epoch: 6 [30000/60000 (50%)]\t1.516960\n",
            "Train Epoch: 6 [32000/60000 (53%)]\t1.541218\n",
            "Train Epoch: 6 [34000/60000 (57%)]\t1.523318\n",
            "Train Epoch: 6 [36000/60000 (60%)]\t1.529634\n",
            "Train Epoch: 6 [38000/60000 (63%)]\t1.508936\n",
            "Train Epoch: 6 [40000/60000 (67%)]\t1.523973\n",
            "Train Epoch: 6 [42000/60000 (70%)]\t1.584364\n",
            "Train Epoch: 6 [44000/60000 (73%)]\t1.521196\n",
            "Train Epoch: 6 [46000/60000 (77%)]\t1.529114\n",
            "Train Epoch: 6 [48000/60000 (80%)]\t1.510424\n",
            "Train Epoch: 6 [50000/60000 (83%)]\t1.535468\n",
            "Train Epoch: 6 [52000/60000 (87%)]\t1.536062\n",
            "Train Epoch: 6 [54000/60000 (90%)]\t1.537388\n",
            "Train Epoch: 6 [56000/60000 (93%)]\t1.542500\n",
            "Train Epoch: 6 [58000/60000 (97%)]\t1.547902\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9695/10000 (97%\n",
            ")\n",
            "Train Epoch: 7 [0/60000 (0%)]\t1.561934\n",
            "Train Epoch: 7 [2000/60000 (3%)]\t1.504258\n",
            "Train Epoch: 7 [4000/60000 (7%)]\t1.552934\n",
            "Train Epoch: 7 [6000/60000 (10%)]\t1.554191\n",
            "Train Epoch: 7 [8000/60000 (13%)]\t1.509452\n",
            "Train Epoch: 7 [10000/60000 (17%)]\t1.526237\n",
            "Train Epoch: 7 [12000/60000 (20%)]\t1.540704\n",
            "Train Epoch: 7 [14000/60000 (23%)]\t1.501209\n",
            "Train Epoch: 7 [16000/60000 (27%)]\t1.526255\n",
            "Train Epoch: 7 [18000/60000 (30%)]\t1.529310\n",
            "Train Epoch: 7 [20000/60000 (33%)]\t1.530991\n",
            "Train Epoch: 7 [22000/60000 (37%)]\t1.498560\n",
            "Train Epoch: 7 [24000/60000 (40%)]\t1.528374\n",
            "Train Epoch: 7 [26000/60000 (43%)]\t1.559659\n",
            "Train Epoch: 7 [28000/60000 (47%)]\t1.529731\n",
            "Train Epoch: 7 [30000/60000 (50%)]\t1.558552\n",
            "Train Epoch: 7 [32000/60000 (53%)]\t1.555910\n",
            "Train Epoch: 7 [34000/60000 (57%)]\t1.526097\n",
            "Train Epoch: 7 [36000/60000 (60%)]\t1.540837\n",
            "Train Epoch: 7 [38000/60000 (63%)]\t1.520240\n",
            "Train Epoch: 7 [40000/60000 (67%)]\t1.550980\n",
            "Train Epoch: 7 [42000/60000 (70%)]\t1.503251\n",
            "Train Epoch: 7 [44000/60000 (73%)]\t1.555349\n",
            "Train Epoch: 7 [46000/60000 (77%)]\t1.539281\n",
            "Train Epoch: 7 [48000/60000 (80%)]\t1.555539\n",
            "Train Epoch: 7 [50000/60000 (83%)]\t1.547414\n",
            "Train Epoch: 7 [52000/60000 (87%)]\t1.518964\n",
            "Train Epoch: 7 [54000/60000 (90%)]\t1.525730\n",
            "Train Epoch: 7 [56000/60000 (93%)]\t1.490923\n",
            "Train Epoch: 7 [58000/60000 (97%)]\t1.528652\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9729/10000 (97%\n",
            ")\n",
            "Train Epoch: 8 [0/60000 (0%)]\t1.513923\n",
            "Train Epoch: 8 [2000/60000 (3%)]\t1.517747\n",
            "Train Epoch: 8 [4000/60000 (7%)]\t1.499109\n",
            "Train Epoch: 8 [6000/60000 (10%)]\t1.509195\n",
            "Train Epoch: 8 [8000/60000 (13%)]\t1.532054\n",
            "Train Epoch: 8 [10000/60000 (17%)]\t1.499590\n",
            "Train Epoch: 8 [12000/60000 (20%)]\t1.522452\n",
            "Train Epoch: 8 [14000/60000 (23%)]\t1.527677\n",
            "Train Epoch: 8 [16000/60000 (27%)]\t1.562587\n",
            "Train Epoch: 8 [18000/60000 (30%)]\t1.493780\n",
            "Train Epoch: 8 [20000/60000 (33%)]\t1.485504\n",
            "Train Epoch: 8 [22000/60000 (37%)]\t1.541285\n",
            "Train Epoch: 8 [24000/60000 (40%)]\t1.525738\n",
            "Train Epoch: 8 [26000/60000 (43%)]\t1.532896\n",
            "Train Epoch: 8 [28000/60000 (47%)]\t1.577564\n",
            "Train Epoch: 8 [30000/60000 (50%)]\t1.559269\n",
            "Train Epoch: 8 [32000/60000 (53%)]\t1.499539\n",
            "Train Epoch: 8 [34000/60000 (57%)]\t1.556360\n",
            "Train Epoch: 8 [36000/60000 (60%)]\t1.547017\n",
            "Train Epoch: 8 [38000/60000 (63%)]\t1.529245\n",
            "Train Epoch: 8 [40000/60000 (67%)]\t1.530187\n",
            "Train Epoch: 8 [42000/60000 (70%)]\t1.552765\n",
            "Train Epoch: 8 [44000/60000 (73%)]\t1.530267\n",
            "Train Epoch: 8 [46000/60000 (77%)]\t1.535061\n",
            "Train Epoch: 8 [48000/60000 (80%)]\t1.515033\n",
            "Train Epoch: 8 [50000/60000 (83%)]\t1.489910\n",
            "Train Epoch: 8 [52000/60000 (87%)]\t1.508071\n",
            "Train Epoch: 8 [54000/60000 (90%)]\t1.537888\n",
            "Train Epoch: 8 [56000/60000 (93%)]\t1.494926\n",
            "Train Epoch: 8 [58000/60000 (97%)]\t1.589683\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9735/10000 (97%\n",
            ")\n",
            "Train Epoch: 9 [0/60000 (0%)]\t1.521569\n",
            "Train Epoch: 9 [2000/60000 (3%)]\t1.517643\n",
            "Train Epoch: 9 [4000/60000 (7%)]\t1.520839\n",
            "Train Epoch: 9 [6000/60000 (10%)]\t1.521855\n",
            "Train Epoch: 9 [8000/60000 (13%)]\t1.538924\n",
            "Train Epoch: 9 [10000/60000 (17%)]\t1.519746\n",
            "Train Epoch: 9 [12000/60000 (20%)]\t1.549556\n",
            "Train Epoch: 9 [14000/60000 (23%)]\t1.521180\n",
            "Train Epoch: 9 [16000/60000 (27%)]\t1.540863\n",
            "Train Epoch: 9 [18000/60000 (30%)]\t1.499195\n",
            "Train Epoch: 9 [20000/60000 (33%)]\t1.536324\n",
            "Train Epoch: 9 [22000/60000 (37%)]\t1.506679\n",
            "Train Epoch: 9 [24000/60000 (40%)]\t1.512007\n",
            "Train Epoch: 9 [26000/60000 (43%)]\t1.503034\n",
            "Train Epoch: 9 [28000/60000 (47%)]\t1.527481\n",
            "Train Epoch: 9 [30000/60000 (50%)]\t1.509988\n",
            "Train Epoch: 9 [32000/60000 (53%)]\t1.506370\n",
            "Train Epoch: 9 [34000/60000 (57%)]\t1.491622\n",
            "Train Epoch: 9 [36000/60000 (60%)]\t1.538184\n",
            "Train Epoch: 9 [38000/60000 (63%)]\t1.503096\n",
            "Train Epoch: 9 [40000/60000 (67%)]\t1.506154\n",
            "Train Epoch: 9 [42000/60000 (70%)]\t1.539592\n",
            "Train Epoch: 9 [44000/60000 (73%)]\t1.536572\n",
            "Train Epoch: 9 [46000/60000 (77%)]\t1.546741\n",
            "Train Epoch: 9 [48000/60000 (80%)]\t1.554037\n",
            "Train Epoch: 9 [50000/60000 (83%)]\t1.493894\n",
            "Train Epoch: 9 [52000/60000 (87%)]\t1.514986\n",
            "Train Epoch: 9 [54000/60000 (90%)]\t1.489842\n",
            "Train Epoch: 9 [56000/60000 (93%)]\t1.573194\n",
            "Train Epoch: 9 [58000/60000 (97%)]\t1.527972\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9765/10000 (98%\n",
            ")\n",
            "Train Epoch: 10 [0/60000 (0%)]\t1.528082\n",
            "Train Epoch: 10 [2000/60000 (3%)]\t1.517272\n",
            "Train Epoch: 10 [4000/60000 (7%)]\t1.473837\n",
            "Train Epoch: 10 [6000/60000 (10%)]\t1.517408\n",
            "Train Epoch: 10 [8000/60000 (13%)]\t1.513471\n",
            "Train Epoch: 10 [10000/60000 (17%)]\t1.499896\n",
            "Train Epoch: 10 [12000/60000 (20%)]\t1.482500\n",
            "Train Epoch: 10 [14000/60000 (23%)]\t1.506453\n",
            "Train Epoch: 10 [16000/60000 (27%)]\t1.545942\n",
            "Train Epoch: 10 [18000/60000 (30%)]\t1.509362\n",
            "Train Epoch: 10 [20000/60000 (33%)]\t1.514352\n",
            "Train Epoch: 10 [22000/60000 (37%)]\t1.548483\n",
            "Train Epoch: 10 [24000/60000 (40%)]\t1.503978\n",
            "Train Epoch: 10 [26000/60000 (43%)]\t1.507788\n",
            "Train Epoch: 10 [28000/60000 (47%)]\t1.497678\n",
            "Train Epoch: 10 [30000/60000 (50%)]\t1.540354\n",
            "Train Epoch: 10 [32000/60000 (53%)]\t1.525270\n",
            "Train Epoch: 10 [34000/60000 (57%)]\t1.551855\n",
            "Train Epoch: 10 [36000/60000 (60%)]\t1.541805\n",
            "Train Epoch: 10 [38000/60000 (63%)]\t1.519691\n",
            "Train Epoch: 10 [40000/60000 (67%)]\t1.553233\n",
            "Train Epoch: 10 [42000/60000 (70%)]\t1.536878\n",
            "Train Epoch: 10 [44000/60000 (73%)]\t1.495746\n",
            "Train Epoch: 10 [46000/60000 (77%)]\t1.515842\n",
            "Train Epoch: 10 [48000/60000 (80%)]\t1.558449\n",
            "Train Epoch: 10 [50000/60000 (83%)]\t1.536151\n",
            "Train Epoch: 10 [52000/60000 (87%)]\t1.529692\n",
            "Train Epoch: 10 [54000/60000 (90%)]\t1.496843\n",
            "Train Epoch: 10 [56000/60000 (93%)]\t1.483907\n",
            "Train Epoch: 10 [58000/60000 (97%)]\t1.540743\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy 9769/10000 (98%\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMgZ0YbqhQjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "data, target = test_data[1] #can change the number for different examples\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "\n",
        "print(f\"Prediction: {prediction}\")\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "qJ82IcC9sly8",
        "outputId": "0d1bf3c6-dcdd-48c7-8f16-d02c026c146e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e1413807968d>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "img = cv2.imread('Examples/8.png',cv2.IMREAD_GRAYSCALE)  #Read the image as a grayscale\n",
        "resized = cv2.resize(img, (28,28))  #Resize the data to the MNIST dimensions\n",
        "features = resized.reshape(1, 28, 28) #Get the image in the form of an array\n",
        "\n",
        "data = torch.tensor(features)\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "data = data.float()\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "\n",
        "print(f\"Prediction: {prediction}\")\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "QSQu6Vz9vAVx",
        "outputId": "32ceb077-62ad-4eb9-d4ec-4f836754ccf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e1413807968d>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}